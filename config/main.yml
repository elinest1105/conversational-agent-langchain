qdrant:
  url: http://qdrant
  # url: http://localhost
  port: 6333
  prefer_grpc: false
  collection_name_aa: aleph_alpha
  collection_name_gpt4all: gpt4all
  collection_name_openai: openai
  collection_name_cohere: cohere
  collection_name_ollama: ollama

# COHERE CONFIG
cohere_completions:
  model_name: "cohere-command"
  maximum_tokens: 300

cohere_embeddings:
  embedding_model_name: "embed-multilingual-v3.0"
  size: 1024

# OLLAMA CONFIG
ollama_embeddings:
  embedding_model_name: "nomic-embed-text"
  size: 768

ollama:
  model: phi3
  size: 768

# (AZURE) OPENAI
openai_embeddings:
  azure: False
  embedding_model_name: text-embedding-ada-002
  size: 1536
  openai_api_version: 2024-02-15-preview

openai_completion:
  model: gpt-3.5-turbo
  temperature: 0
  max_tokens: 500
  top_p: 1
  frequency_penalty: 0
  presence_penalty: 0
  stop: None


# ALEPH ALPHA CONFIG
aleph_alpha_embeddings:
  normalize: True
  size: 5120
  compress_to_size: null
  model_name: "luminous-base"

aleph_alpha_completion:
  model: "luminous-extended-control"
  temperature: 0
  max_tokens: 200
  top_p: 0 # not used must be changed in aleph alpha service send_completion_request
  frequency_penalty: 0 # not used must be changed in aleph alpha service send_completion_request
  presence_penalty: 0 # not used must be changed in aleph alpha service send_completion_request
  best_of: 1 # not used must be changed in aleph alpha service send_completion_request
  repetition_penalties_include_prompt: True # not used must be changed in aleph alpha service send_completion_request
  stop_sequences: "###"
  repetition_penalties_include_completion: True

# GPT4ALL Config
gpt4all_completion:
  completion_model: "orca-mini-3b-gguf2-q4_0.gguf" # "mistral-7b-openorca.Q4_0.gguf"

gpt4all_embeddings:
  size: 1024
